{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper code to reload source files automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from event_clustering.preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Preprocessing Analyzing\n",
    "- load and preprocess the dataset\n",
    "- analyze the dataset to determine which features you want to generate and how they should be encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column name map to suit your dataset by replacing the values in this dictionary \n",
    "column_name_map = {\n",
    "    'timestamp': 'time:timestamp',\n",
    "    'caseid' : 'case:id',\n",
    "    'eventname' : 'concept:name',\n",
    "    'resource' : 'org:resource',\n",
    "    'role' : 'org:role'\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and preprocess the dataset\n",
    "\n",
    "# specify your data folder and the filename you want to analyze\n",
    "data_folder = 'data/'\n",
    "file_name = 'DomesticDeclarations'\n",
    "df = preprocess(load(data_folder + file_name + '.xes'), column_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the structure and some highlevel insights on the dataset\n",
    "# set include_casetime to true if you want to get insights about the length and duration of the cases in your dataset\n",
    "analyze(df, column_name_map, show_examples=False, include_casetime=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation\n",
    "- generate the additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a reference and the calculated timediference to neighboring events of each event.\n",
    "add_neighbor_event(df, 1, column_name_map)\n",
    "add_neighbor_event(df, -1, column_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one hot encoded start, middle and end events using neighbor reference\n",
    "add_event_position_relative_feature(df, column_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one hot encoded start and end events using window length. Insert the desired window in seconds\n",
    "add_event_position_window_feature(df, column_name_map, start_window_length=3600, end_window_length=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one hot encoded time of day features\n",
    "add_time_of_day_feature(df, column_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df with generated features as csv, so it can be used in the next step:\n",
    "df.to_csv(data_folder + file_name +'_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding\n",
    "- encode the features you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe with features already added (see previous step)\n",
    "df = preprocess(pd.read_csv(data_folder + file_name +'_features.csv'), column_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = tfidf_encode(df, column_name_map['eventname'], TfidfVectorizer(stop_words = 'english'))\n",
    "\n",
    "# features depending on dataset \n",
    "df_role = one_hot_encode(df, column_name_map['role'])\n",
    "#df_resource = one_hot_encode(df, column_name_map['resource'])\n",
    "\n",
    "# generated features\n",
    "df_position_relative = df[['feature_position_relative_beginning', 'feature_position_relative_middle', 'feature_position_relative_end']]\n",
    "df_position_window = df[['feature_position_window_start', 'feature_position_window_end']]\n",
    "df_time_to_successor = binning(df, 'neighbor_event_timedif_1', 10, 'feature_time_to_successor')\n",
    "df_time_of_day = df[filter_column_names(df, 'feature_time_of_day')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the features you want to combine to your final vector\n",
    "\n",
    "df_encoded = df_name\n",
    "df_encoded = df_encoded.join(df_role)\n",
    "df_encoded = df_encoded.join(df_position_relative)\n",
    "df_encoded = df_encoded.join(df_position_window)\n",
    "df_encoded = df_encoded.join(df_time_to_successor)\n",
    "df_encoded = df_encoded.join(df_time_of_day)\n",
    "\n",
    "# features \n",
    "#df_encoded = df_encoded.join(df_resource)\n",
    "#df_encoded = df_encoded.join(df[\"case:SUMleges\"].fillna(0))\n",
    "#df_encoded = df_encoded.join(df_act_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the encoded events as csv, so it can be used in the evaluation:\n",
    "\n",
    "df_encoded.to_csv(data_folder + file_name +'_encoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
