{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload source files automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from event_clustering.preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Preprocessing Analyzing\n",
    "- load and preprocess the dataset\n",
    "- analyze the dataset to determine which features you want to generate and how they should be encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column name map to suit your dataset\n",
    "column_name_map = {\n",
    "    'timestamp': 'time:timestamp',\n",
    "    'caseid' : 'case:id',\n",
    "    'eventname' : 'concept:name'   \n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and preprocess the dataset\n",
    "file_name = 'DomesticDeclarations'\n",
    "df = preprocess(load('data/' + file_name + '.xes'), column_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df.columns:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the structure and some highlevel insights on the dataset\n",
    "analyze(df, column_name_map, show_examples=True, include_casetime=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation\n",
    "- generate the features you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features for neighboring events and timedif to these neighbors\n",
    "\n",
    "add_neighbor_event(df, 1)\n",
    "#add_neighbor_event(df, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one hot encoded start, middle and end events using neighbor reference\n",
    "\n",
    "#determine_start_end_event_feature(df, column_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one hot encoded start and end events using window length. Insert the desired window in seconds\n",
    "\n",
    "determine_time_frame_feature(df, column_name_map, start_window_length=3600, end_window_length=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_timestamp_features(df, column_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df with generated features as csv, so it can be used in the next step:\n",
    "\n",
    "df.to_csv('data/' + file_name +'_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding\n",
    "- encode the features you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe with features already added (see previous step)\n",
    "\n",
    "df = preprocess(pd.read_csv('data/' + file_name +'_features.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = tfidf_encode(df, 'concept:name', TfidfVectorizer(stop_words = 'english'))\n",
    "#df_act_name = tfidf_encode(df, 'activityNameEN', TfidfVectorizer(stop_words = 'english'))\n",
    "#df_resource = one_hot_encode(df, 'org:resource')\n",
    "#df_role = one_hot_encode(df, 'org:role')\n",
    "\n",
    "#df_time_window = df[['feature_in_start_window', 'feature_in_end_window']]\n",
    "#df_time = binning(df, 'feature_timedif_neighbor_event_-1', 10)\n",
    "#df_time_of_day = df[filter_column_names(df, 'feature_time_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment lines to add more features you want to use in your encoding:\n",
    "\n",
    "df_encoded = df_name\n",
    "#df_encoded = df_encoded.join(df_resource)\n",
    "#df_encoded = df_encoded.join(df[\"case:SUMleges\"].fillna(0))\n",
    "#df_encoded = df_encoded.join(df_act_name)\n",
    "#df_encoded = df_encoded.join(df_role)\n",
    "#df_encoded = df_encoded.join(df_event_position)\n",
    "#df_encoded = df_encoded.join(df_time)\n",
    "#df_encoded = df_encoded.join(df['feature_day_nr'])\n",
    "#df_encoded = df_encoded.join(df_time_of_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the encoded events as csv, so it can be used in the evaluation:\n",
    "# file_name_structure: [Dataset-name]_[Feature-groups]_encoded.csv\n",
    "\n",
    "df_encoded.to_csv('data/' + file_name +'_name-cost-act-tod_encoded.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
